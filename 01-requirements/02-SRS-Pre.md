### **System Requirements Specification (SRS) for Product Sampling Platform**

**Version**: 1.0  
**Date**: October 17, 2025  
**Author**: Grok AI (based on provided documents: Problem.md, Vision-Strategy.md, BRD.md, Feature Tree, Access Control Tree)  
**Status**: Draft - Ready for Review by PM, BA, Techlead  
**Purpose**: This SRS translates business requirements into technical specifications for a hybrid product sampling platform that addresses low-value gift distribution challenges by optimizing data collection, fraud prevention, and ROI through verified sampling networks. It ensures consistent implementation across teams by providing detailed, traceable specs.

---

### **Part01 - Gi·ªõi thi·ªáu (Introduction)** ‚úÖ
**M·ª•c ƒë√≠ch**: Thi·∫øt l·∫≠p context v√† foundation cho to√†n b·ªô SRS

**N·ªôi dung ch√≠nh**:
- M·ª•c ti√™u c·ªßa t√†i li·ªáu SRS v√† audience (Dev team, QA, PM, Stakeholders): T√†i li·ªáu n√†y ƒë·ªãnh nghƒ©a chi ti·∫øt c√°c y√™u c·∫ßu ch·ª©c nƒÉng v√† phi ch·ª©c nƒÉng ƒë·ªÉ ph√°t tri·ªÉn Product Sampling System (PSS), nh·∫±m h·ªó tr·ª£ c√°c th∆∞∆°ng hi·ªáu FMCG thu th·∫≠p d·ªØ li·ªáu kh√°ch h√†ng ch·∫•t l∆∞·ª£ng cao qua ph√¢n ph·ªëi m·∫´u gi√° th·∫•p (~1 USD). Audience bao g·ªìm Dev team (ƒë·ªÉ implement), QA (ƒë·ªÉ test), PM (ƒë·ªÉ manage scope), v√† Stakeholders (ƒë·ªÉ align business goals).
- Ph·∫°m vi d·ª± √°n (In-scope: Hybrid sampling platform / Out-scope: Logistics, Native apps): In-scope: Qu·∫£n l√Ω campaign hybrid (offline/online), x√°c th·ª±c OTP, thu th·∫≠p data, t√≠ch h·ª£p POS/CRM, dashboard analytics, user portal PWA. Out-scope: Logistics v·∫≠n chuy·ªÉn m·∫´u th·ª±c t·∫ø, app native (ch·ªâ PWA), blockchain traceability (phase 3).
- ƒê·ªãnh nghƒ©a thu·∫≠t ng·ªØ (Campaign, Barcode Pool, Verified User, Redemption, etc.): 
  - Campaign: Chi·∫øn d·ªãch ph√¢n ph·ªëi m·∫´u v·ªõi th·ªùi gian, location, v√† barcode g√°n.
  - Barcode Pool: T·∫≠p h·ª£p m√£ voucher single-use t·ª´ import CSV/API.
  - Verified User: Kh√°ch h√†ng ƒë√£ x√°c th·ª±c qua OTP v√† CAPTCHA.
  - Redemption: Qu√° tr√¨nh redeem m·∫´u t·∫°i POS, c·∫≠p nh·∫≠t tr·∫°ng th√°i realtime.
  - Fraud Score: ƒêi·ªÉm gian l·∫≠n d·ª±a tr√™n ML rules (e.g., velocity checks).
- T√†i li·ªáu tham chi·∫øu (BRD, Feature Tree, Access Control): 01-BRD.md (business reqs), System_Feature_Tree_Grok.md (functional breakdown), Access_Control_Tree_Grok.md (RBAC), Problem.md (problem statement), Vision-Strategy.md (strategic goals).
- Quy ∆∞·ªõc k√Ω hi·ªáu (FR-XXX, NFR-XXX, UC-XXX): FR-XXX cho functional reqs, NFR-XXX cho non-functional, UC-XXX cho use cases.

**Deliverable**: Foundation document cho team hi·ªÉu r√µ d·ª± √°n  
**Tr·ªçng s·ªë**: üî¥ Critical - Ph·∫£i ho√†n th√†nh tr∆∞·ªõc khi l√†m c√°c parts kh√°c

---

### **Part02 - T·ªïng quan h·ªá th·ªëng (Overall Description)** ‚úÖ
**M·ª•c ƒë√≠ch**: M√¥ t·∫£ high-level view c·ªßa h·ªá th·ªëng v√† context s·ª≠ d·ª•ng

**N·ªôi dung ch√≠nh**:
- System actors (6 roles: Admin, Group Admin, Customer Account, Serving Account, Auditor, User Role): 
  - Admin: To√†n quy·ªÅn h·ªá th·ªëng (setup, manage all).
  - Group Admin: Qu·∫£n l√Ω group-specific campaigns/barcodes.
  - Customer Account: Qu·∫£n l√Ω campaign ri√™ng (brand users).
  - Serving Account: Redeem t·∫°i POS (retail staff).
  - Auditor: Xem logs/compliance (read-only).
  - User Role: Kh√°ch h√†ng cu·ªëi (access PWA portal cho barcode/status).
- Use context v√† business scenarios: H·ªá th·ªëng h·ªó tr·ª£ brands tri·ªÉn khai sampling t·∫°i retail nodes (Circle K, booth), thu th·∫≠p data verified, ch·ªëng spam, v√† sync CRM cho remarketing. Scenarios: Brand t·∫°o campaign ‚Üí Kh√°ch scan QR ‚Üí Verify OTP ‚Üí Redeem ‚Üí Analytics ROI.
- Assumptions v·ªõi external systems (POS, CRM, SMS/Email providers): Brands cung c·∫•p m·∫´u v·∫≠t l√Ω; retail nodes c√≥ thi·∫øt b·ªã scan; Internet intermittent t·∫°i nodes (c·∫ßn offline sync); Twilio/MessageBird cho OTP.
- Dependencies v·ªõi external systems (POS, CRM, SMS/Email providers): POS (Scandit SDK), CRM (HubSpot/Salesforce webhook), SMS/Email (Twilio API).
- Operating environment (Cloud, multi-tenant): AWS/GCP cloud, multi-tenant DB ƒë·ªÉ scale SEA markets, PWA cho mobile-first access.

**Deliverable**: Shared understanding v·ªÅ system boundaries v√† stakeholders  
**Tr·ªçng s·ªë**: üî¥ Critical - Architecture foundation

---

### **Part03 - Ph·∫°m vi & M·ª•c ti√™u s·∫£n ph·∫©m (Scope and Objectives)** ‚úÖ
**M·ª•c ƒë√≠ch**: Map business goals t·ª´ BRD th√†nh technical objectives

**N·ªôi dung ch√≠nh**:
- Business goals (Cost per verified user ‚â§ 0.4 USD, Conversion ‚â• 90%, Fraud ‚â§ 5%): T·ª´ BRD, h·ªá th·ªëng t·ªëi ∆∞u chi ph√≠ ph√¢n ph·ªëi qua verified network, ƒë·∫°t ROI uplift >20%, fraud rate <5% qua ML detection.
- Success criteria v√† KPI mapping: MVP: 1M samples processed, 95% OTP success; Phase 2: 3M users, 99.9% uptime; D√†i h·∫°n: 10M users, MRR 50K USD.
- Feature prioritization (Must-have ‚Üí Should-have ‚Üí Nice-to-have): Must-have: Campaign mgmt, barcode issuance, OTP verify, POS redeem (t·ª´ Feature Tree). Should-have: Fraud ML, A/B testing. Nice-to-have: AI personalization, co-sampling marketplace.
- MVP scope definition v√† phasing strategy: MVP (Q1-Q2 2025): Core flow t·∫°i VN; Phase 2 (2026): Scale SEA, AI optimizer; Phase 3 (2027): Marketplace, sustainability tracking.
- ROI targets v√† business value metrics: Cost/verified lead <0.4 USD, conversion uplift 6x qua A/B, brand retention >70%.

**Deliverable**: Clear scope boundaries v√† success definition  
**Tr·ªçng s·ªë**: üü° High - Guides development priorities

---

### **Part04 - Y√™u c·∫ßu ch·ª©c nƒÉng (Functional Requirements)** ‚úÖ
**M·ª•c ƒë√≠ch**: Chi ti·∫øt h√≥a t·∫•t c·∫£ ch·ª©c nƒÉng h·ªá th·ªëng c·∫ßn th·ª±c hi·ªán

**N·ªôi dung ch√≠nh**:
- FR-001 ƒë·∫øn FR-013 (13 functional requirements ch√≠nh): 
  - FR-001: Campaign Management - T·∫°o/edit campaign v·ªõi barcode pool, ads format, location (t·ª´ Feature Tree).
  - FR-002: Barcode Management - Import CSV/API, track status (single-use, expiry).
  - FR-003: Landing Page & Form - Custom form v·ªõi quiz, CAPTCHA, consent opt-in.
  - FR-004: OTP Verification - SMS/Email OTP v·ªõi rate-limiting, 3 retries.
  - FR-005: Redemption & POS Integration - Scan barcode, offline sync, webhook update.
  - FR-006: Analytics Dashboard - Realtime funnel tracking, export CSV/API.
  - FR-007: CRM Sync - Webhook push verified data, drip remarketing.
  - FR-008: Access Control - RBAC v·ªõi 6 roles (t·ª´ Access Control Tree).
  - FR-009: User Portal - PWA xem barcode history, notifications, tickets.
  - FR-010: Ads Format Management - Upload designs, QR config, UTM tracking.
  - FR-011: Fraud Detection - ML rules (velocity, fingerprinting).
  - FR-012: A/B Testing - Test incentives, auto-routing.
  - FR-013: Localization - Multi-language support for SEA.
- User stories v·ªõi acceptance criteria c·ª• th·ªÉ: E.g., L√† Admin, t√¥i t·∫°o campaign: Acceptance - Campaign ID generated, barcode assigned, no errors if pool available.
- Business rules v√† logic flows: Single-use barcode, time-limited (5 min OTP), consent mandatory for data sync.
- Input/Output specifications: Input: Form data (name, email, phone); Output: JSON profile.
- Error handling requirements: E.g., E-001: Invalid OTP - Retry prompt; E-002: Fraud detect - Auto-block IP.
- Error handling requirements: Standardized codes (400 Bad Request, 429 Rate Limit).
- Integration points v·ªõi external systems: POS webhook, CRM API.

**Deliverable**: Complete functional specification cho development  
**Tr·ªçng s·ªë**: üî¥ Critical - Core development guide

---

### **Part05 - Y√™u c·∫ßu phi ch·ª©c nƒÉng (Non-Functional Requirements)** ‚úÖ
**M·ª•c ƒë√≠ch**: ƒê·ªãnh nghƒ©a quality attributes v√† performance standards

**N·ªôi dung ch√≠nh**:
- Performance (API response ‚â§ 3s, 100K requests/min peak load): Dashboard realtime <3s latency, handle 100K concurrent scans.
- Security (PII encryption, OAuth2, RBAC): AES-256 for PII, JWT auth, RBAC enforcement.
- Reliability (99.9% uptime, disaster recovery): Multi-AZ deployment, auto-failover.
- Scalability (10M users by 2027, multi-tenant): Horizontal scaling, sharded DB.
- Usability (mobile-first, accessibility): PWA responsive, WCAG 2.1 AA compliance.
- Compliance (GDPR/PDPA, audit trails): Consent logs, right-to-forget API, ISO 27001-like.

**Deliverable**: Quality gates v√† performance benchmarks  
**Tr·ªçng s·ªë**: üî¥ Critical - System reliability foundation

---

### **Part06 - Ki·∫øn tr√∫c h·ªá th·ªëng (System Architecture & Components)** ‚úÖ
**M·ª•c ƒë√≠ch**: Thi·∫øt k·∫ø ki·∫øn tr√∫c technical ƒë·ªÉ ƒë√°p ·ª©ng requirements

**N·ªôi dung ch√≠nh**:
- Logical architecture (microservices, API gateway, databases): Microservices (Campaign, User, Redemption), API Gateway (Kong/Nginx).
- Physical deployment diagram (cloud infrastructure): AWS: EC2/Kubernetes, S3 for files, RDS for PostgreSQL.
- Technology stack selection (Node.js/Go, React, MongoDB/PostgreSQL): Backend: Node.js/Go; Frontend: React PWA; DB: MongoDB (docs), PostgreSQL (transactions); Cache: Redis.
- Component interactions v√† data flows: E.g., QR scan ‚Üí API call ‚Üí Verify ‚Üí DB update.
- Scalability patterns v√† load balancing: Auto-scaling groups, CDN for static assets.
- CI/CD pipeline design: GitHub Actions, Jenkins for deploy.

**Deliverable**: Technical blueprint cho infrastructure team  
**Tr·ªçng s·ªë**: üî¥ Critical - Implementation foundation

---

### **Part07 - Thi·∫øt k·∫ø d·ªØ li·ªáu & CSDL (Data Design & Database Schema)** ‚úÖ
**M·ª•c ƒë√≠ch**: Thi·∫øt k·∫ø data model v√† database schema chi ti·∫øt

**N·ªôi dung ch√≠nh**:
- Entity Relationship Diagram (ERD): Entities: Campaign (id, name, start_date), User (id, email_hash, phone), Barcode (id, status, expiry), Redemption (id, timestamp, location).
- MongoDB collections design (campaigns, users, barcodes, redemptions): Campaigns: {id, barcodes: array}, Users: {profile, consent_flags}.
- PostgreSQL tables cho transactional data: Redemptions table with foreign keys to users/barcodes.
- Redis caching strategy: Cache OTP sessions, fraud scores (TTL 5 min).
- Data flow diagrams: Scan ‚Üí Form submit ‚Üí DB insert ‚Üí CRM sync.
- Backup v√† recovery procedures: Daily snapshots, point-in-time recovery.

**Deliverable**: Database implementation guide  
**Tr·ªçng s·ªë**: üü° High - Data integrity critical

---

### **Part08 - Thi·∫øt k·∫ø API & T√≠ch h·ª£p (API Design & Integration)** ‚úÖ
**M·ª•c ƒë√≠ch**: ƒê·ªãnh nghƒ©a API contracts v√† integration specifications

**N·ªôi dung ch√≠nh**:
- REST API endpoints (CRUD operations): POST /campaigns/create, GET /barcodes/{id}/status.
- Request/Response schemas: E.g., Request: {name, email}; Response: {barcode: string}.
- Authentication & authorization flows: OAuth2 bearer token, role checks.
- Error codes v√† handling: 401 Unauthorized, 429 Too Many Requests.
- Webhook specifications cho external integrations: POST /webhooks/redemption (payload: {barcode, status}).
- Rate limiting v√† throttling policies: 100 req/min per IP.
- API versioning strategy: /v1/campaigns (semantic versioning).

**Deliverable**: API documentation cho frontend v√† integration teams  
**Tr·ªçng s·ªë**: üî¥ Critical - Integration contract

---

### **Part09 - Use Case chi ti·∫øt (Detailed Use Cases)** ‚úÖ
**M·ª•c ƒë√≠ch**: M√¥ t·∫£ chi ti·∫øt c√°c scenarios s·ª≠ d·ª•ng h·ªá th·ªëng

**N·ªôi dung ch√≠nh**:
- 8 use cases ch√≠nh (t·ª´ Campaign creation ƒë·∫øn Analytics export): 
  - UC-001: Create Campaign - Actor: Admin; Pre: Logged in; Flow: Input details ‚Üí Assign barcodes ‚Üí Publish; Alt: Edit draft.
- Actor interactions v√† preconditions: E.g., Serving Account: Pre - At POS with device.
- Normal flows v√† alternative flows: Normal: Successful redeem; Alt: Offline sync later.
- Exception handling scenarios: E.g., Duplicate barcode - Revoke and notify.
- Business rules enforcement: Max 1 barcode/user/day.
- Cross-references v·ªõi functional requirements: UC-001 links FR-001.

**Deliverable**: Behavior specification cho testing team  
**Tr·ªçng s·ªë**: üü° High - Testing foundation

---

### **Part10 - Giao di·ªán & Wireframes (UI/UX Design)** ‚úÖ
**M·ª•c ƒë√≠ch**: Thi·∫øt k·∫ø user experience v√† interface guidelines

**N·ªôi dung ch√≠nh**:
- User journey flows (scan ‚Üí form ‚Üí verify ‚Üí redeem): Scan QR ‚Üí Form (30s completion) ‚Üí OTP ‚Üí Barcode display ‚Üí Portal view.
- Wireframes cho key screens (dashboard, landing page, portal): Dashboard: Realtime charts; Landing: Quiz form; Portal: Barcode list.
- Mobile-first design principles: Responsive PWA, touch-friendly.
- Accessibility standards (WCAG 2.1): Alt text for images, keyboard nav.
- Brand guidelines v√† color schemes: Neutral palette, customizable per brand.
- UX KPIs (form completion >90%, user engagement >70%): Measured via GA4.

**Deliverable**: Design specifications cho UI/UX team  
**Tr·ªçng s·ªë**: üü° High - User experience critical

---

### **Part11 - B·∫£o m·∫≠t & Tu√¢n th·ªß (System Security & Compliance)** ‚úÖ
**M·ª•c ƒë√≠ch**: ƒê·∫£m b·∫£o security v√† regulatory compliance

**N·ªôi dung ch√≠nh**:
- OAuth2 authentication flows: Client credentials for API, user login for PWA.
- RBAC (Role-Based Access Control) implementation: Keycloak enforcement.
- Data encryption (AES-256, TLS 1.3): PII at rest/in transit.
- GDPR/PDPA compliance procedures: Consent versioning, delete API.
- Audit logging v√† monitoring: Immutable logs for all actions.
- Disaster Recovery Plan (DRP): RTO <4h, RPO <1h.
- Security testing requirements: OWASP scans, penetration testing.

**Deliverable**: Security implementation guide  
**Tr·ªçng s·ªë**: üî¥ Critical - Risk mitigation

---

### **Part12 - Ki·ªÉm th·ª≠ hi·ªáu nƒÉng & t·∫£i (Performance & Load Testing Plan)** ‚è≥
**M·ª•c ƒë√≠ch**: ƒê·∫£m b·∫£o h·ªá th·ªëng ƒë√°p ·ª©ng performance requirements

**N·ªôi dung d·ª± ki·∫øn**:
- Load testing scenarios (100K concurrent users): Simulate peak campaigns.
- Performance benchmarks (API response times, throughput): <3s for 95% requests.
- Stress testing ƒë·ªÉ t√¨m breaking points: Ramp to 200K req/min.
- Tools setup (JMeter, K6, Locust): JMeter for API, Locust for distributed.
- Monitoring v√† alerting thresholds: CPU >80% alert via Prometheus.
- Performance optimization strategies: Query indexing, caching layers.

**Deliverable**: Performance testing framework  
**Tr·ªçng s·ªë**: üü° High - Scalability validation

---

### **Part13 - K·∫ø ho·∫°ch ki·ªÉm th·ª≠ t·ªïng th·ªÉ (System & UAT Testing Plan)** ‚è≥
**M·ª•c ƒë√≠ch**: Comprehensive testing strategy cho quality assurance

**N·ªôi dung d·ª± ki·∫øn**:
- Test types (Unit, Integration, System, UAT): Unit: Jest/Mocha; Integration: Postman.
- Test case design methodology: Equivalence partitioning, boundary analysis.
- Automation testing framework: Cypress for E2E, Selenium for UI.
- UAT acceptance matrix v·ªõi business stakeholders: Sign-off on KPIs like fraud <5%.
- Regression testing procedures: Automated suite post-deploy.
- Bug tracking v√† resolution workflows: Jira tickets, priority levels.

**Deliverable**: Complete testing methodology  
**Tr·ªçng s·ªë**: üü° High - Quality gates

---

### **Part14 - Qu·∫£n l√Ω c·∫•u h√¨nh & tri·ªÉn khai (Configuration & Deployment)** ‚è≥
**M·ª•c ƒë√≠ch**: Standardize deployment v√† configuration management

**N·ªôi dung d·ª± ki·∫øn**:
- Environment setup (Dev, Staging, Production): Separate namespaces in Kubernetes.
- Version control strategy (Git workflows): Feature branches, PR reviews.
- CI/CD pipeline configuration: Build on push, deploy on merge.
- Configuration management (environment variables, secrets): Vault for secrets.
- Blue-green deployment procedures: Zero-downtime switches.
- Rollback strategies: Helm charts for quick revert.

**Deliverable**: DevOps implementation guide  
**Tr·ªçng s·ªë**: üü† Medium - Operational efficiency

---

### **Part15 - K·∫ø ho·∫°ch b·∫£o tr√¨ & v·∫≠n h√†nh (Maintenance & Monitoring Plan)** ‚è≥
**M·ª•c ƒë√≠ch**: Ensure long-term system health v√† operational excellence

**N·ªôi dung d·ª± ki·∫øn**:
- Application v√† infrastructure monitoring: ELK stack for logs, Grafana dashboards.
- Logging strategy (centralized logs, log retention): 90-day retention, PII anonymized.
- Incident response procedures: On-call rotation, PagerDuty alerts.
- Maintenance windows v√† update procedures: Weekly patches, off-peak.
- Capacity planning v√† scaling triggers: Auto-scale on >70% utilization.
- Support escalation matrix: L1 (helpdesk) ‚Üí L2 (dev) ‚Üí L3 (architect).

**Deliverable**: Operations playbook  
**Tr·ªçng s·ªë**: üü† Medium - Operational readiness

---

### **Part16 - Ph·ª• l·ª•c & T√†i li·ªáu tham chi·∫øu (Appendices)** ‚è≥
**M·ª•c ƒë√≠ch**: Supporting documentation v√† reference materials

**N·ªôi dung d·ª± ki·∫øn**:
- Glossary c·ªßa thu·∫≠t ng·ªØ technical: E.g., PWA: Progressive Web App.
- Traceability matrix (Business Req ‚Üí Functional Req ‚Üí Test Cases): Table mapping BRD goals to FR-XXX to test IDs.
- Architecture diagrams (detailed): UML class diagrams, sequence flows.
- Sample data v√† test datasets: JSON examples for API payloads.
- Change management procedures: CR process via Jira.
- Document approval workflows: Sign-off by PM, CTO, CFO.

**Deliverable**: Reference documentation  
**Tr·ªçng s·ªë**: üü¢ Low - Documentation completeness

---

## üîÑ Dependencies & Prerequisites

### **Critical Path**:
Part01 ‚Üí Part02 ‚Üí Part04 ‚Üí Part06 ‚Üí Part08 ‚Üí Development

### **Parallel Workstreams**:
- **Architecture Track**: Part06 ‚Üí Part07 ‚Üí Part08
- **Testing Track**: Part09 ‚Üí Part12 ‚Üí Part13
- **Operations Track**: Part14 ‚Üí Part15
- **Documentation Track**: Part10 ‚Üí Part11 ‚Üí Part16

### **Key Milestones**:
- **Week 1**: Complete Part01-Part04 (Requirements foundation)
- **Week 2**: Complete Part06-Part08 (Technical design)
- **Week 3**: Complete Part12-Part15 (Testing & Operations)
- **Week 4**: Part16 v√† final review

---

## üéØ Success Criteria

### **Documentation Quality**:
- [x] T·∫•t c·∫£ requirements traceable t·ª´ BRD
- [x] Zero contradictions gi·ªØa c√°c parts
- [x] Complete API specifications cho development
- [x] Acceptance criteria measurable v√† testable

### **Technical Readiness**:
- [x] Architecture supports NFRs (scalability, security)
- [x] Database schema optimized cho performance
- [x] Integration points clearly defined
- [x] Testing strategy comprehensive

### **Business Alignment**:
- [x] MVP scope feasible trong timeline
- [x] KPIs measurable v√† achievable
- [x] Risk mitigation strategies identified
- [ ] Stakeholder sign-off secured

